\chapter{Instances}
\label{Instances}

As virtualization is a fairly recent field, there are no good, established set of benchmark instances available for that problem. The properties of physical substrate networks and virtual network embedding requests are not well understood \cite{Chowdhury:2012}. Hence most works use synthetic networks for evaluation \cite{FischerSurvey}. 

There are many variations of the Virtual Network Embedding Problem. Each author devise their own method of generating random networks according to the variant of the problem. This section presents an overview of some of the methods used in the literature and the approach taken by this work.

The main approach taken to evaluate VNEP algorithms is to create a simulation environment. A physical substrate network and random virtual networks are randomly generated over a window of time. The approach of the current work is to evaluate each virtual network request individually, obtaining an exact optimal solution. 

Real networks available online do not subsume all characteristics that can be incorporated in a VNEP problem. Therefore, two approaches are taken in the literature. The first is using wholly synthetic networks. The second is to use real network topologies and aggregating the necessary traits into them.

\section{Synthetic Graphs}
GT-ITM is the most used tool to generate random networks topologies \cite{Fischer}. Many works use it by extending its capabilities to work with other constraints.

There are three types of topologies that this tool can generate:

\paragraph{Random Graphs $(L, \alpha, \beta)$} \todoc{explain parameters} The nodes are spread uniformly on a $L$ by $L$ plane. The nodes are linked randomly using the Waxman model [?]. In this model, the probability of connecting two edges is $ \alpha e^{- d / (\beta L) }$, where $d$ is the euclidean distance between the nodes. Thus, a larger $\alpha$ means a denser graph, and a larger $\beta$ means more longer edges are present in the graph.

\paragraph{Hierarchical Networks $(k, L, S, \alpha, \beta)$} Topologies of this type are generated recursively. Initially a random graph is generated like explained above. Each node is replaced with a new graph. The process is repeated $k$ times, the number of levels.
%TODO explain Scale
   
\paragraph{Transit-Stub $(\alpha)$} The Transit-stub model is the one that best models the current Internet, which is a series of interconnected domains\cite{Zagura:1996}. These domains can be either transit or stub domains. Stub domains can connect only nodes within its domain.

First, a initial random graph is generated. Each node is a transit domain. Those nodes are replaced by a random graph. To these domains are attached small stub domains. The transit domains are connected randomly as well as the sub domains. So a stub domain can be connected to more than one transit domain.

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{exsparse}
                \caption{Sparse Random}
                \label{fig:gensparse}
        \end{subfigure}%
        ~ 
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{exdense}
                \caption{Dense Random}
                \label{fig:gendense}
        \end{subfigure}

        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{exhier}
                \caption{Hierarchical}
                \label{fig:genhier}
        \end{subfigure}
        ~ 
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{exts}
                \caption{Transit-Stub}
                \label{fig:gents}
        \end{subfigure}
        \caption{Topologies}\label{fig:topo}
\end{figure}
\section{Hybrid approach}

A different approach is taken by \cite{infuhr:2011}. The physical substrate graphs are extracted from two sets of topologies available online. Subgraphs are first extracted from those topologies. Afterwards, nodes are removed from them in order to generate graphs of the proper sizes. Bandwidth capacities of 25 were incorporated to the arcs.

The virtual network requests were randomly generated by aggregating ``slices'' of networks. Those slices are small networks divided in four different kinds. These kinds are based on common network use cases: Web Slices, Stream Slices, P2P Slices, and  VoIP Slices. New slices are aggregated until CPLEX would not find an integer solution for the instance in less than 300 seconds in five tries.

\section{Instance Sizes}
As a benchmark set is not available for the VNEP, this work uses randomly generated bandwidth capacities and demands. Table~\ref{tab:band} contains some of the main papers and the sizes of graphs and the values of bandwidth used in their evaluations.

  In works that have multiple test configurations, we show the heaviest.

  \begin{table}[h]
  \begin{center}
    \small
    \caption{Problem Characteristics}\label{tab:band}
    \begin{tabular}{l c c c c c c}
    Reference             & $|S|$       & $|V|$     & $V_{cap}$  & $V_{dem}$ & $E_{cap}$   & $E_{dem}$      \\
    \hline
    \citet{Alkmim:2011}    & $[5,25] $   & $[5,10]$  & 256        & 128       & $[1,10]$    & $[0.1,0.4]$    \\
    \citet{Buriol:2012}    & $[50,100]$  & $[17,66]$ & 100        & $[1,50]$  & $[1,10]$    & $[0.1,5]$      \\
    \citet{Botero:2012}    & $15$        & $5$       & NA         & $[0,100]$ & NA          & $[0,100]$      \\ 
    \citet{Chowdhury2010}  & $50$        & $[2,10]$  & $[50,100]$ & $[0,20]$  & $[50,100]$   & $[0,50]$     \\
    \citet{Houidi:2011}    & $50$        & $[2,10]$  & $[50,100]$ & $[0,20]$  & $[50,100]$   & $[0,50]$     \\
    \citet{hu:2013}        & $[10,50]$   & $[2,10]$  & $[1,50]$   & $[1,20]$  & $[1,50]$     & $[1,20]$     \\
    \citet{infuhr:2011}    & $[20,100]$  & $[2,20]$  & $[25,100]$ & $[1,5]$ & $[25,100]$     & $[1,7]$        \\
    \citet{Pages:2012}     & $16$        & $[3,4]$   & 0          &  0        & 8           & 1              \\
    \citet{Guerzoni:2014}  & $[50,250]$  & $[2,5]$   & $[50,100]$ & $[1,10]$  & $[50,100]$  & $[1,25]$       \\
  \end{tabular}
\end{center}
\end{table}

%Botero et al. - the absolute values of processing power and capacities of the physical network are played in such a way as to make the sum of all requests occupy 20\% to 90\% of its resources.

\section{Evaluation Approach}
\todoi{describe the types of instances used on the evaluation}
